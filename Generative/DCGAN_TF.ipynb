{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6OZ7FGt07TyM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oo6Xngf7bXn",
        "outputId": "fa1409f1-0f28-4ac9-b497-52fc9f85770f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-nncl5llx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-nncl5llx\n",
            "  Resolved https://github.com/tensorflow/docs to commit 6680535155460f7eb0d2d615b9749a0cf721d4ec\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==2024.5.3.31743)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.5.3.31743) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.5.3.31743) (3.1.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.5.3.31743) (5.10.4)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.5.3.31743) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.5.3.31743) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.5.3.31743) (2.1.5)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.5.3.31743) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.5.3.31743) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.5.3.31743) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.5.3.31743) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.5.3.31743) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.5.3.31743) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.5.3.31743) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.5.3.31743) (0.19.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2024.5.3.31743) (4.2.2)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2024.5.3.31743-py3-none-any.whl size=182531 sha256=1d23021e48762a0b633131e2e04dd40a70cc9d92e5bf441bb8ed93479587bdfe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-av235b35/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-2024.5.3.31743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "fXumPRqY7fSW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_imgs, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz2qTTu27urI",
        "outputId": "c370a476-8ab4-4e68-d5bc-098993b62ad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = train_imgs.reshape(train_imgs.shape[0], 28, 28, 1).astype('float32')\n",
        "train_imgs = (train_imgs - 127.5) / 127.5  # normalize to [-1, 1]"
      ],
      "metadata": {
        "id": "xCl4WTo5711o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SZ = 60_000\n",
        "BATCH_SZ = 256\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs).shuffle(BUFFER_SZ).batch(BATCH_SZ)"
      ],
      "metadata": {
        "id": "jZ49Y6gA8Ddi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100, )))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7, 7, 256)\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  # (batch size, same shape cuz same padding, num filters)\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  # 7x7 -> 14x14 cuz same padding + double stride (2, 2)\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False,\n",
        "                                   activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "nlylYwV88H9E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "bHTbNyc59ga9",
        "outputId": "28e3c5b6-bdcf-4d7b-842f-0a8fb8fca758"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x785f0b6c2ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                          input_shape=[28, 28, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "55mYQy569qmt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator()\n",
        "\n",
        "decision = discriminator(generated)\n",
        "print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19PHy3l2-LWb",
        "outputId": "4108b2e0-84b7-4c9c-e12d-8d80f76c0d0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00110828]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "kYatYPlN-Ywa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real, fake):\n",
        "  # should output all 1s when input is real\n",
        "  real_loss = cross_entropy(tf.ones_like(real), real)\n",
        "  # should output all 0s when input is fake\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake), fake)\n",
        "\n",
        "  total = real_loss + fake_loss\n",
        "  return total"
      ],
      "metadata": {
        "id": "2pGIis37-kTU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake):\n",
        "  # generator should trick the discriminator\n",
        "  # => discriminator should output 1s (say it's real)\n",
        "  return cross_entropy(tf.ones_like(fake), fake)"
      ],
      "metadata": {
        "id": "9e3Pp1-T-5nc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optim = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optim = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "f81ALgHT_P7h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optim=generator_optim,\n",
        "    discriminator_optim=discriminator_optim,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator\n",
        ")"
      ],
      "metadata": {
        "id": "RjxmJfvC_V0x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# will reuse this seed so it's easier to visualize progress in the GIF\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "ZKgLGEzG_n5_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(imgs):\n",
        "  noise = tf.random.normal([BATCH_SZ, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_imgs = generator(noise, training=True)\n",
        "\n",
        "    real_out = discriminator(imgs, training=True)\n",
        "    fake_out = discriminator(generated_imgs, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_out)\n",
        "    disc_loss = discriminator_loss(real_out, fake_out)\n",
        "\n",
        "  gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optim.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
        "  discriminator_optim.apply_gradients(zip(disc_grads, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "hFvzBXZk_4W0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # run layers in inference mode (batchnorm)\n",
        "  preds = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(preds[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig(f\"image__epoch_{epoch:04d}.png\")\n",
        "  plt.show()\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for idx, img_batch in enumerate(dataset):\n",
        "      # print(f\"Running {idx}\")\n",
        "      train_step(img_batch)\n",
        "\n",
        "    # display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch+1, seed)\n",
        "\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} took {time.time() - start}s\")\n",
        "\n",
        "  # display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "metadata": {
        "id": "2vL_vOWWAgLY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "500zYAxsBbq1",
        "outputId": "a1bb7af2-edb6-45b4-b6ea-3110186a6c74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 0\n",
            "Running 1\n",
            "Running 2\n",
            "Running 3\n",
            "Running 4\n",
            "Running 5\n",
            "Running 6\n",
            "Running 7\n",
            "Running 8\n",
            "Running 9\n",
            "Running 10\n",
            "Running 11\n",
            "Running 12\n",
            "Running 13\n",
            "Running 14\n",
            "Running 15\n",
            "Running 16\n",
            "Running 17\n",
            "Running 18\n",
            "Running 19\n",
            "Running 20\n",
            "Running 21\n",
            "Running 22\n",
            "Running 23\n",
            "Running 24\n",
            "Running 25\n",
            "Running 26\n",
            "Running 27\n",
            "Running 28\n",
            "Running 29\n",
            "Running 30\n",
            "Running 31\n",
            "Running 32\n",
            "Running 33\n",
            "Running 34\n",
            "Running 35\n",
            "Running 36\n",
            "Running 37\n",
            "Running 38\n",
            "Running 39\n",
            "Running 40\n",
            "Running 41\n",
            "Running 42\n",
            "Running 43\n",
            "Running 44\n",
            "Running 45\n",
            "Running 46\n",
            "Running 47\n",
            "Running 48\n",
            "Running 49\n",
            "Running 50\n",
            "Running 51\n",
            "Running 52\n",
            "Running 53\n",
            "Running 54\n",
            "Running 55\n",
            "Running 56\n",
            "Running 57\n",
            "Running 58\n",
            "Running 59\n",
            "Running 60\n",
            "Running 61\n",
            "Running 62\n",
            "Running 63\n",
            "Running 64\n",
            "Running 65\n",
            "Running 66\n",
            "Running 67\n",
            "Running 68\n",
            "Running 69\n",
            "Running 70\n",
            "Running 71\n",
            "Running 72\n",
            "Running 73\n",
            "Running 74\n",
            "Running 75\n",
            "Running 76\n",
            "Running 77\n",
            "Running 78\n",
            "Running 79\n",
            "Running 80\n",
            "Running 81\n",
            "Running 82\n",
            "Running 83\n",
            "Running 84\n",
            "Running 85\n",
            "Running 86\n",
            "Running 87\n",
            "Running 88\n",
            "Running 89\n",
            "Running 90\n",
            "Running 91\n",
            "Running 92\n",
            "Running 93\n",
            "Running 94\n",
            "Running 95\n",
            "Running 96\n",
            "Running 97\n",
            "Running 98\n",
            "Running 99\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d152560ca122>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-5534235c28cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running {idx}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# display.clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "jXgZc-CcBdeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open(f\"image__epoch_{epoch_no:04d}\")\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "with imageio.get_write(anim_file, mode=\"I\") as writer:\n",
        "  filenames = sorted(glob.glob('image*.png'))\n",
        "\n",
        "  for filename in filenames:\n",
        "    img = imageio.imread(filename)\n",
        "    writer.append_data(img)\n",
        "\n",
        "  img = imageio.imread(filename)\n",
        "  writer.append_data(img)"
      ],
      "metadata": {
        "id": "27e9ao4ZBwQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ],
      "metadata": {
        "id": "Fy4HYvHsCXT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}